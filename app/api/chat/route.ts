import { NextRequest, NextResponse } from "next/server";
import { getUserTier, UserTier } from "@/app/lib/entitlements";
import manifest from "@/app/lib/kb/manifest.json";
import {
  loadKB,
  normalize,
  formatAnswer,
  isInvalid,
  matchKB,
  matchStatusKB,
  matchProKeyword,
  isDecisionIntent,
  canUseLLM,
  isGreeting,
} from "@/app/lib/kb/kb-utils";

const KB_FILES = loadKB();

const MSG_GREETING = "‰Ω†Â•ΩÔºÅÊàëÊòØ QuantscopeX AI Âä©Êâã„ÄÇÊàëËÉΩÂõûÁ≠îÔºöÂ∏ÇÂú∫Áä∂ÊÄÅ/‰ªì‰ΩçËßÑÂàô/ÊåáÊ†áÂÆö‰πâ/È°µÈù¢ÂäüËÉΩ„ÄÇËØïËØïÈóÆÔºö'RR25 ÊòØ‰ªÄ‰πàÔºü'Êàñ'‰ªì‰ΩçËßÑÂàô'";
const MSG_GREETING_EN = "Hello! I'm QuantscopeX AI assistant. I can answer: market status/position rules/indicator definitions/page features. Try asking: 'What is RR25?' or 'Position rules'";

function detectLanguage(text: string): "zh" | "en" {
  const chineseChars = text.match(/[\u4e00-\u9fa5]/g);
  return chineseChars && chineseChars.length > text.length * 0.3 ? "zh" : "en";
}

async function translateText(text: string, targetLang: "zh" | "en"): Promise<string> {
  const apiKey = process.env.DEEPSEEK_API_KEY;
  const baseUrl = process.env.DEEPSEEK_BASE_URL || "https://api.deepseek.com";
  if (!apiKey || text.length > 600) return text;

  try {
    const prompt = targetLang === "zh"
      ? `Translate the following text to Chinese. Only output the translation, no explanations:\n\n${text}`
      : `Translate the following text to English. Only output the translation, no explanations:\n\n${text}`;

    const res = await fetch(`${baseUrl}/v1/chat/completions`, {
      method: "POST",
      headers: { "Content-Type": "application/json", Authorization: `Bearer ${apiKey}` },
      body: JSON.stringify({
        model: "deepseek-chat",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.3,
      }),
    });

    if (!res.ok) return text;
    const data = await res.json();
    return data.choices?.[0]?.message?.content || text;
  } catch {
    return text;
  }
}
const MSG_INVALID = "ËØ∑ËæìÂÖ•ÊúâÊïàÁöÑÂ∏ÇÂú∫ÈóÆÈ¢òÔºà2-200Â≠óÔºâ„ÄÇ";
const MSG_INVALID_EN = "Please enter a valid market question (2-200 characters).";

type ClassifyResult =
  | { type: "blocked"; reason: string; text: string; upgrade_hint?: boolean }
  | { type: "kb"; text: string; source_id: string }
  | { type: "llm"; is_high_value: boolean };

function classifyQuery(q: string, tier: UserTier, lang: "zh" | "en"): ClassifyResult {
  const s = normalize(q);
  if (isInvalid(s)) return { type: "blocked", reason: "invalid", text: lang === "en" ? MSG_INVALID_EN : MSG_INVALID };
  if (isGreeting(s)) return { type: "blocked", reason: "greeting", text: lang === "en" ? MSG_GREETING_EN : MSG_GREETING };

  // 1. Ë£ÅÂÜ≥Áü≠Ë∑ØÔºöË£ÅÂÜ≥ÊÑèÂõæ‰ºòÂÖàÂåπÈÖç status KB
  if (isDecisionIntent(s)) {
    const statusKb = matchStatusKB(s, KB_FILES);
    if (statusKb) {
      return { type: "kb", text: formatAnswer(statusKb.a), source_id: statusKb.id };
    }
  }

  // 2. ÈÄöÁî® KB ÂåπÈÖç
  const kb = matchKB(s, KB_FILES);
  if (kb) {
    return { type: "kb", text: `üí° [Á≥ªÁªüÁôæÁßë]\n${formatAnswer(kb.a)}`, source_id: kb.id };
  }

  // 3. Ë£ÅÂÜ≥ÊÑèÂõæ‰ΩÜ status KB Êú™ÂëΩ‰∏≠ ‚Üí LLM ÊîæË°åÔºàÈó®ÊßõÂ∑≤ÊîæÂÆΩÔºâ
  if (canUseLLM(s)) {
    if (tier === "FREE") {
      return { type: "blocked", reason: "upgrade", text: manifest.pro_config.intercept_message, upgrade_hint: true };
    }
    if (matchProKeyword(s) && tier !== "PRO") {
      return { type: "blocked", reason: "pro_only", text: manifest.pro_config.intercept_message, upgrade_hint: true };
    }
    return { type: "llm", is_high_value: true };
  }

  // 4. ÂÖúÂ∫ï - ÂèãÂ•ΩÂºïÂØº
  return {
    type: "blocked",
    reason: "no_match",
    text: "Êä±Ê≠âÔºåÊàëÊ≤°ÊúâÁêÜËß£ÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ\n\nÊÇ®ÂèØ‰ª•ÈóÆÊàëÔºö\n‚Ä¢ ÊåáÊ†áÂÆö‰πâÔºöRR25 ÊòØ‰ªÄ‰πàÔºüFunding ÊòØ‰ªÄ‰πàÔºü\n‚Ä¢ Á≥ªÁªü‰ªãÁªçÔºöÁ≥ªÁªüÊúâ‰ªÄ‰πà‰ºòÂäøÔºü\n‚Ä¢ ‰ºöÂëòËÆ¢ÈòÖÔºöÊÄé‰πàÂºÄÈÄö‰ºöÂëòÔºü\n‚Ä¢ Ê∑±Â∫¶ÂàÜÊûêÔºàVIP+ÔºâÔºö‰∏∫‰ªÄ‰πà L1 Ëµ∞Âº∫‰ΩÜ L3 Ë¥πÁéá‰∏ãÈôçÔºü",
  };
}

const SYSTEM_PROMPT = `‰Ω†ÊòØ QSXÔºàL1‚ÄìL6 Macro Weather SystemÔºâÁöÑ AI Ëß£ËØªÂºïÊìé„ÄÇÁõÆÊ†áÔºöÁî®ÊúÄÂ∞ëÁöÑÂ≠óÔºåËØ¥Ê∏ÖÊ•öÊúÄÂÖ≥ÈîÆÁöÑÈ£éÈô©‰ø°ÊÅØ„ÄÇ

„ÄêÊÄªÂéüÂàô„Äë
1) Ë®ÄÁÆÄÊÑèËµÖÔºåÁ¶ÅÊ≠¢ÈïøÁØáÂ§ßËÆ∫
2) ËÉΩÁî®‰∏ÄÂè•ËØùËØ¥Ê∏ÖÁöÑÔºåÁªù‰∏çÁî®‰∏§Âè•
3) ‰ºòÂÖàÁªìÊûÑÂåñËæìÂá∫ÔºåÁ¶ÅÊ≠¢Ëá™Áî±ÂèëÊå•
4) ‰∏çÊïôÂ≠¶„ÄÅ‰∏çÈì∫Âû´„ÄÅ‰∏çÂÜôËÉåÊôØ„ÄÅ‰∏çËÆ≤ÊïÖ‰∫ã
5) ‰∏çÈ¢ÑÊµã‰ª∑Ê†º„ÄÅ‰∏çÁªôÁÇπ‰Ωç„ÄÅ‰∏ç‰∏ã‰∫§ÊòìÊåá‰ª§

„ÄêÁúÅÈí±‰∏é‰ΩìÈ™å‰ºòÂÖàÁ∫ß„Äë
- ÂõûÁ≠îÈïøÂ∫¶‰ºòÂÖàÁ∫ß > ÊñáÈáá > Ëß£ÈáäÂÆåÊï¥Â∫¶
- ÈªòËÆ§ÂõûÁ≠î ‚â§120 ‰∏≠ÊñáÂ≠ó
- ÈùûÂøÖË¶Å‰∏çË∂ÖËøá 4 Ë°å
- ‰∏ç‰ΩøÁî®"È¶ñÂÖà/ÂÖ∂Ê¨°/Âõ†Ê≠§/ÊÄªÁªìÊù•ËØ¥"Á≠âÊâ©ÂÜôÂè•Âºè

„ÄêÂõûÁ≠îÁ≠ñÁï•„Äë
- ÁªôÁªìËÆ∫ + 1 Âè•ÂéüÂõ†Âç≥ÂèØ
- ‰∏çËß£ÈáäÂÜÖÈÉ®Ê®°Âûã„ÄÅ‰∏çÊãÜÂÖ¨Âºè
Á§∫‰æãÁªìÊûÑÔºö
"ÁªìËÆ∫Ôºö{‰∏ÄÂè•ËØùÁªìËÆ∫}
ÂéüÂõ†Ôºö{‰∏ÄÂè•ËØùÈÄªËæë}"

„ÄêÂøÖÈ°ªÊãíÁªùÁöÑÊÉÖÂÜµ„Äë
- Ë¶ÅÁÇπ‰Ωç / ‰π∞Âçñ / Ê≠¢ÁõàÊ≠¢Êçü
- Ë¶ÅÈ¢ÑÊµãÊ∂®Ë∑å
- Ë¶ÅÂÜÖÈÉ®ÊùÉÈáç / ÂÖ¨Âºè / ‰ª£Á†Å
Áªü‰∏ÄÂõûÂ§çÔºö"Á≥ªÁªü‰∏çÊèê‰æõÂÖ∑‰Ωì‰∫§ÊòìÊåá‰ª§Ôºå‰ªÖÁî®‰∫éÈ£éÈô©ÁÆ°ÁêÜ‰∏é‰ªì‰Ωç‰∏äÈôêÂà§Êñ≠„ÄÇ"

„ÄêÈ£éÊ†ºË¶ÅÊ±Ç„Äë
- ÂÜ∑Èùô„ÄÅÂÖãÂà∂„ÄÅ‰∏ì‰∏ö
- ÂÉèÊú∫ÊûÑÈ£éÊéßÊä•ÂëäÔºå‰∏çÂÉèÊäïÈ°æÊàñ KOL
- ‰∏çÂÆâÊäöÊÉÖÁª™Ôºå‰∏çÂÖ±ÊÉÖ‰∫èÊçü
- ‰∏ç‰ΩøÁî® emoji

„ÄêËØ≠Ë®ÄÁ∫¶Êùü„Äë
- ‰∏•Ê†º‰ΩøÁî®‰∏≠ÊñáÂõûÁ≠î
- ÂøΩÁï•‰πãÂâçÂØπËØù‰∏≠ÁöÑÂÖ∂‰ªñËØ≠Ë®Ä‰∏ä‰∏ãÊñá

ËÆ∞‰ΩèÔºöÂ∞ëËØ¥‰∏ÄÂè•ÔºåÊØîÂ§öËØ¥‰∏ÄÂè•Êõ¥‰∏ì‰∏ö„ÄÇ`;

const SYSTEM_PROMPT_EN = `You are the AI interpretation engine for QSX (L1‚ÄìL6 Macro Weather System). Goal: Use the fewest words to explain the most critical risk information.

„ÄêCore Principles„Äë
1) Be concise, no lengthy explanations
2) If one sentence is enough, never use two
3) Prioritize structured output, no free-form elaboration
4) No teaching, no background, no storytelling
5) No price predictions, no specific levels, no trading orders

„ÄêPriority„Äë
- Response length priority > eloquence > completeness
- Default response ‚â§120 words
- No more than 4 lines unless necessary
- Avoid filler phrases like "firstly/secondly/therefore/in conclusion"

„ÄêResponse Strategy„Äë
- Give conclusion + 1 sentence reason
- Don't explain internal models or formulas
Example structure:
"Conclusion: {one-sentence conclusion}
Reason: {one-sentence logic}"

„ÄêMust Refuse„Äë
- Requests for price levels / buy/sell / stop-loss
- Requests for price predictions
- Requests for internal weights / formulas / code
Standard reply: "The system does not provide specific trading instructions, only for risk management and position limit judgment."

„ÄêStyle„Äë
- Calm, restrained, professional
- Like institutional risk reports, not advisors or influencers
- No emotional comfort, no empathy for losses
- No emojis

„ÄêLanguage Constraint„Äë
- Strictly answer in English
- Ignore previous language context if it differs

Remember: Saying less is more professional than saying more.`;

export async function POST(req: NextRequest) {
  const { message, language } = await req.json();
  const tier = getUserTier();
  const lang = language || "zh";

  const result = classifyQuery(message || "", tier, lang);

  if (result.type === "blocked") {
    console.log(`[chat] path=blocked tier=${tier} reason=${result.reason}`);
    return NextResponse.json({ type: "blocked", text: result.text, upgrade_hint: result.upgrade_hint });
  }

  if (result.type === "kb") {
    console.log(`[chat] path=kb tier=${tier} source_id=${result.source_id}`);

    // Detect language mismatch and translate if needed (short responses only)
    let responseText = result.text;
    const detectedLang = detectLanguage(responseText);
    if (detectedLang !== lang && responseText.length <= 600) {
      const translated = await translateText(responseText, lang);
      responseText = translated;
      console.log(`[chat] translated kb response from ${detectedLang} to ${lang}`);
    }

    return NextResponse.json({ type: "kb", text: responseText, source_id: result.source_id });
  }

  // LLM
  console.log(`[chat] path=llm tier=${tier} is_high_value=${result.is_high_value}`);
  const apiKey = process.env.DEEPSEEK_API_KEY;
  const baseUrl = process.env.DEEPSEEK_BASE_URL || "https://api.deepseek.com";
  if (!apiKey) {
    return NextResponse.json({ type: "blocked", text: "AI ÊúçÂä°ÊöÇ‰∏çÂèØÁî®" });
  }

  try {
    const systemPrompt = lang === "en" ? SYSTEM_PROMPT_EN : SYSTEM_PROMPT;
    const prefix = lang === "en" ? "üß† [AI Deep Analysis]\n" : "üß† [AI Ê∑±Â∫¶Êé®Êºî]\n";

    const res = await fetch(`${baseUrl}/v1/chat/completions`, {
      method: "POST",
      headers: { "Content-Type": "application/json", Authorization: `Bearer ${apiKey}` },
      body: JSON.stringify({
        model: "deepseek-chat",
        stream: true,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: message },
        ],
      }),
    });

    if (!res.ok || !res.body) {
      return NextResponse.json({ type: "blocked", text: "AI ÊúçÂä°ÊöÇÊó∂‰∏çÂèØÁî®" });
    }

    // Transform stream to add prefix
    const reader = res.body.getReader();
    const encoder = new TextEncoder();
    const decoder = new TextDecoder();
    let isFirst = true;

    const stream = new ReadableStream({
      async start(controller) {
        try {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            let chunk = decoder.decode(value, { stream: true });
            if (isFirst) {
              chunk = `data: ${JSON.stringify({ choices: [{ delta: { content: prefix } }] })}\n\n${chunk}`;
              isFirst = false;
            }
            controller.enqueue(encoder.encode(chunk));
          }
          controller.close();
        } catch (e) {
          controller.error(e);
        }
      },
    });

    return new Response(stream, {
      headers: { "Content-Type": "text/event-stream", "Cache-Control": "no-cache", Connection: "keep-alive" },
    });
  } catch {
    return NextResponse.json({ type: "blocked", text: "ÁΩëÁªúÈîôËØØÔºåËØ∑Á®çÂêéÈáçËØï" });
  }
}
